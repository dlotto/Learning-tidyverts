---
title: "Learning tidyverts with Rob Hyndman"
output: html
---
IMPORTANT: This document will follow closely along the PDF from the Rob J Hyndman website. Located here:
https://robjhyndman.com/seminars/tidyverts2021/
**This is a learning exercise. I do not claim this as original work**

For more information: tidyverts.org 
Forecasting: Principle and Practice: https://otexts.com/fpp3

The title of the presentation is "Feasts & fables: Time series analysis using R"

```{r setup}
library(magrittr)
library(tsibble)
library(tsibbledata)
library(feasts)
library(fable)
library(ggplot2)
library(fpp3)
```
# tsibble: Time series data
<section>

## Examine a tsibble
The features of a tsibble object are the Index, the Key, and the Measured Variables.
In this case, for the global_economy table, we have Year (index), Country (key), and GDP, Imports, etc (measured variables).
```{r examine a tsibble}
global_economy
```

### tsibble objects
A tsibble allows storage and manipulation of multiple time series in R. And it works with tidyverse functions!

* Index: Time information about the observation
* Key(s): optional unique identifiers for each series.
* Measured Variables: numbers of interest

## Converting to a tsibble object

* Convert the ymd<date> into the Quarter<qrt> variable
* Remove the ymd variable.
* Convert to tsibble. Set the 'index' to the <qrt> and the unique identifying 'keys'.
```{r converting to tsibble}
prison <- readr::read_csv("tidyverts2021/data/prison_population.csv", show_col_types = FALSE) %>% 
  dplyr::mutate(Quarter = tsibble::yearquarter(date)) %>% 
  dplyr::select(-date) %>% 
  tsibble::as_tsibble(
    index = Quarter,
    key = c(state, gender, legal, indigenous)
  )
```

### tsibble indexes
Common time index variable can be created with these functions.
```{r tsibble indexes}
# Quarterly -   tsibble::yearquarter()
# Monthly -     tsibble::yearmonth()
# Weekly -      tsibble::yearweek()
# Daily -       lubridate::as_date(), lubridate::ymd()
# Sub-daily -   lubridate::as_datetime()
```

# feasts: Data visualization
<section>

## Australian holidays

```{r}
holidays <- tourism %>% 
  dplyr::filter(Purpose == "Holiday") %>% 
  dplyr::group_by(State) %>% 
  dplyr::summarise(Trips = sum(Trips)) %>% 
  dplyr::mutate(
    State = case_when(State == "New South Wales" ~ "NSW",
                      State == "Northern Territory" ~ "NT",
                      State == "Queensland" ~ "QLD",
                      State == "South Australia" ~ "SA",
                      State == "Tasmania" ~ "TAS",
                      State == "Victoria" ~ "VIC",
                      State == "Western Australia" ~ "WA",
                      TRUE ~ State
    ))
```

## Time Plots

* Plotted against time: autoplot() (each series overplotted)
* Plotted against season: gg_season() (facet by key)
* Plotted against time with seasonal facets: gg_subseries() (facet by key)

### autoplot
```{r}
library(ggplot2)
holidays %>% autoplot(Trips) +
  ylab("thousands of trips") +
  ggtitle("Australian domestic holiday nights")
```

### gg_season
```{r}
holidays %>% feasts::gg_season(Trips) +
  ylab("thousands of trips") +
  ggtitle("Australian domestic holiday nights")
```

### gg_subseries
```{r}
holidays %>% feasts::gg_subseries(Trips) +
  ylab("thousands of trips") +
  ggtitle("Australian domestic holiday nights")
```

## Victorian Electricity Demand
```{r}
vic_elec %>% feasts::gg_season(Demand)
vic_elec %>% feasts::gg_season(Demand, period = "week")
vic_elec %>% feasts::gg_season(Demand, period = "day")
```

## Autocorrelations
```{r acf plots}
holidays %>% 
  feasts::ACF(Trips) %>% 
  ggplot2::autoplot()
```
### Google stock price
```{r}
google_2015 <- gafa_stock %>% 
  dplyr::filter(Symbol == "GOOG",
                lubridate::year(Date) == 2015) %>% 
  dplyr::select(Date, Close)

google_2015 %>% autoplot(Close)
```
#### Handling irregular data
```{r}
google_2015 %>% 
  ACF(Close, lag_max = 100) %>% 
  autoplot()
```

# feasts: Time series features
Seasonal and trend decomposition using Loess (STL)
y(t) = T(t)+S(t)+R(t)

Loess is a method for estimating nonlinear relationships. 

Taken from https://stats.stackexchange.com/questions/294981/how-does-loess-decomposition-work
> The basic idea of the loess smoother is pretty simple. If we have inputs x and response y, to get an estimate at x0, we first compute the weight distances of the points of x from x0 and then perform linear regression, where we downweight values of x that are farther away from x0. Our weighted regression model at xo then provides our loess estimate. You can also include polynomial expansions of x as well.

* Use a type of sliding window to divide the data into smaller blobs.
* At each data point, use weighted least squares to fit a line.
* Then, to reduce the influence of outliers, create an additional weight for the weighted least squares. This additional weight is based on how far the original point (x) is from the new point (x0).
* You can fit a line or a parabola to the points in the window.

## Basic STL Decomposition
```{r}
fpp3::canadian_gas %>% 
  stl(t.window = 12, s.window = "periodic", robust = TRUE) %>% 
  plot()
```

## fabletools STL Decomposition
From https://otexts.com/fpp3/stl.html
> By default, the `STL()` function provides a convenient automated STL decomposition using a seasonal window of `season(window = 13)`, and the trend window chosen automatically from the seasonal period. The default session for monthly data is `trend(window=21)`. This usually gives a good balance between overfitting the seasonality and allowing it to slowly change over time. 
In the case below, the defaut trend window setting produces a trend-cycle component that is too rigid. As a result, the signal from the 2008 GFC has leaked into the remainder component. Selecting a shorter trend window improves this.

```{r retail_emp data setup}
us_retail_employment <- fpp3::us_employment %>% 
  dplyr::filter(Title == "Retail Trade", lubridate::year(Month) >= 1990) %>%
  dplyr::select(-Series_ID)
```

### Decomposition components
```{r}
dcmp <- us_retail_employment %>% 
  fabletools::model(stl = feasts::STL(Employed))

fabletools::components(dcmp)
```

### Overlay trend component
```{r}
components(dcmp) %>% 
  as_tsibble() %>% 
  autoplot(Employed, color = "gray") +
  geom_line(aes(y=trend), color = "#D55E00") +
  labs(
    y = "Persons (thousands)",
    title = "Total employment in US retail"
  )
```

### Plotting the components
Plotting all the components with `autoplot`
```{r}
us_retail_employment %>% 
  fabletools::model(
    feasts::STL(Employed ~ trend(window = 7) + season(window = "periodic"),
                robust = TRUE)) %>% 
  fabletools::components() %>% 
  ggplot2::autoplot()
```


## Feature extraction and statistics

### Plotting trend and seasonal strength
```{r}
tourism %>% 
  fabletools::features(Trips, feasts::feat_stl) %>% 
  ggplot2::ggplot(aes(x = trend_strength, y = seasonal_strength_year, col = Purpose)) +
  ggplot2::geom_point() +
  ggplot2::facet_wrap(vars(State))
```

### Find the most seasonal time series
```{r}
most_seasonal <- tourism %>% 
  fabletools::features(Trips, features = feat_stl) %>% 
  dplyr::filter(seasonal_strength_year == max(seasonal_strength_year))

tourism %>% 
  dplyr::right_join(most_seasonal, by = c("State","Region","Purpose")) %>% 
  ggplot2::ggplot(aes(x = Quarter, y = Trips)) +
  ggplot2::geom_line() +
  ggplot2::facet_grid(vars(State, Region, Purpose))
```

### Find the most trended time series
```{r}
most_trended <- tourism %>% 
  fabletools::features(Trips, features = feat_stl) %>% 
  filter(trend_strength == max(trend_strength))

tourism %>% 
  right_join(most_trended, by = c("State","Region","Purpose")) %>% 
  ggplot(aes(x = Quarter, y = Trips)) +
  geom_line() +
  facet_grid(vars(State, Region, Purpose))
```

### All features from feasts package

```{r}
tourism_features <- tourism %>% 
  features(Trips, feature_set(pkgs = "feasts"))
```

Now we apply some *principle components* based on all features from the feasts package

#### How to do PCA
https://builtin.com/data-science/step-step-explanation-principal-component-analysis

* Standardize the range of continuous initial variables
* Compute the covariance matrix to identify correlations
* Compute the eigenvectors and eigenvalues of the covariance matrix to identify the principle components
* Create a feature vector to decide which principle components to keep
* Recast the data along the principle components axes

```{r}
pcs <- tourism_features %>% 
  select(-State, -Region, -Purpose) %>% 
  stats::prcomp(scale = TRUE) %>% 
  broom::augment(tourism_features)

# Principle components based on all the features from the feasts package
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2)) +
  geom_point() +
  theme(aspect.ratio = 1)
```

The Purpose of the travel appears to be a driving factor in the feature vector.
```{r}
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2, col = Purpose)) +
  geom_point() +
  theme(aspect.ratio = 1)
```

# fable: Forecasting
A forecast is an estimate of the probability distribution of a variable to be observed in the future.

## Model fitting
```{r}
holiday_fit <- holidays %>% 
  fabletools::model(
    snaive = fable::SNAIVE(Trips),
    naive = fable::NAIVE(Trips),
    ets = fable::ETS(Trips),
    arima = fable::ARIMA(Trips)
  )
```

```{r}
holiday_fit %>% 
  filter(State == "VIC") %>% 
  select(arima) %>% 
  fabletools::report()
```

```{r}
fabletools::glance(holiday_fit)
fabletools::tidy(holiday_fit)
fabletools::augment(holiday_fit)
```
## Ljung-Box Test
```{r}
augment(holiday_fit) %>% 
  filter(State == "VIC", .model == "arima") %>% 
  features(.resid, feasts::ljung_box, dof = 2, lag = 8)
```

## TS Residuals
```{r}
holiday_fit %>% 
  filter(State == "VIC") %>% 
  select(arima) %>% 
  feasts::gg_tsresiduals()
```

## Producing forecasts
```{r}
holiday_fc <- holiday_fit %>% 
  fabletools::forecast(h = "2 years")

vic_fc <- holiday_fc %>% 
  filter(State == "VIC")
```

## Visualizing forecasts
```{r}
holiday_fc %>% 
  filter(State == "VIC") %>% 
  autoplot(holidays, level = NULL) %>% 
  labs(title = "Holidays in Victoria", y = "Thousands of visitors") %>%  
  guides(color = guide_legend(title = "Forecast"))
```


```{r}
holiday_fc %>% 
  filter(State == "VIC", .model == "arima") %>% 
  autoplot(holidays) %>% 
  labs(title = "Holidays in Victoria", y = "Thousands of visitors") %>%  
  guides(color = guide_legend(title = "Forecast"))
```

## Prediction intervals

* Point forecasts often useless without a measure of uncertainty (such as prediction intervals)
* Prediction intervals require a stochastic model (with random errors, etc)
* For most models, prediction intervals get wider as the forecast horizon increases
* Use `level` an argument to control coverage
* Check residual assumptions before believing them
* Usually too narrow due to unaccounted uncertainty
```{r}
holiday_fc %>% fabletools::hilo(level = 95)
```

# fable: Evaluating forecast accuracy

* A model which fits the training data well will not necessarily forecast well.
* A perfect fit can always be obtained by using a model with enough parameters.
* Over-fitting a model to data is just as bad as failing to identify a systematic pattern in the data.
* The test set must not be used for **any** aspect of a model development or calculation of forecasts.
* Forecast accuracy is based only on the test set.

```{r}
# Not sure why this isn't working correctly
fabletools::accuracy(holiday_fc, holidays)
```

## Time series cross-validation
Stretch with a minimum length of 4 years, growing by 1 quarter each step.
```{r}
vic_holiday_stretch <- holidays %>% 
  filter(State == "VIC") %>% 
  tsibble::stretch_tsibble(.init = 16, .step = 1)

vic_holiday_stretch
```


```{r}
fit_cv <- vic_holiday_stretch %>% 
  model(
    ets = ETS(Trips),
    arima = ARIMA(Trips),
    snaive = SNAIVE(Trips)
  )
```

```{r}
fc_cv <- fit_cv %>% 
  forecast(h = 1)
```

A good way to choose the best forecasting model is to find the model with the smallest RMSE computed using time series cross-validation
```{r}
fc_cv %>% accuracy(holidays)
```







